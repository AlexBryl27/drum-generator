{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "answering-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import LeakyReLU, Dropout, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.layers import Conv1DTranspose, Activation, Embedding\n",
    "from tensorflow.keras.layers import Concatenate, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "clinical-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import guitarpro\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.markov_chain import MarkovChain\n",
    "from src.parse_gp import drop_rests_from_drum_track, get_notes_and_durations\n",
    "from src.save_midi import save_notes_and_durations, save_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "animated-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = \"tabs/\"\n",
    "use_durations = True\n",
    "track_name = 'guitar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grave-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7520a720f674659af0598ea7fa03c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes, durations = [], []\n",
    "for folder in os.listdir(folderpath):\n",
    "    for filename in tqdm(os.listdir(folderpath + folder + '/')):\n",
    "        tab = guitarpro.parse(folderpath + folder + '/' + filename)\n",
    "        tab_notes, tab_durations = get_notes_and_durations(tab, track_name, False)\n",
    "        notes += tab_notes\n",
    "        durations += tab_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "focal-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[143, 64, 103, 142, 92, 218, 64, 103, 142, 92]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_dictionary = {note: i for i, note in enumerate(set(notes))}\n",
    "inv_note_dictionary = {i: note for note, i in note_dictionary.items()}\n",
    "notes_to_int = [note_dictionary[note] for note in notes]\n",
    "notes_to_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forced-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_dictionary = {dur: i for i, dur in enumerate(set(durations))}\n",
    "inv_dur_dictionary = {i: dur for dur, i in duration_dictionary.items()}\n",
    "durations_to_int = [duration_dictionary[dur] for dur in durations]\n",
    "durations_to_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "textile-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, durations, length, step, n_notes, n_durations):\n",
    "    note_sequences = []\n",
    "    note_targets = []\n",
    "    dur_sequences = []\n",
    "    dur_targets = []\n",
    "    for i in range(0, len(notes) - length, step):\n",
    "        note_sequences.append(notes[i: i + length])\n",
    "        note_targets.append(notes[i + length])\n",
    "        dur_sequences.append(durations[i: i + length])\n",
    "        dur_targets.append(durations[i + length])\n",
    "    note_targets = to_categorical(note_targets, n_notes)    \n",
    "    dur_targets = to_categorical(dur_targets, n_durations)\n",
    "    sequences = [np.array(note_sequences), np.array(dur_sequences)]\n",
    "    targets = [note_targets, dur_targets]\n",
    "    return sequences, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "weighted-employment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1556, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = prepare_sequences(notes_to_int, durations_to_int, 128, 4, len(note_dictionary), len(duration_dictionary))\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "affecting-syracuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1556, 226)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "irish-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder(Model):\n",
    "    def __init__(self, encoder, decoder, loss_factor):\n",
    "        super(ModelBuilder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.loss_factor = loss_factor\n",
    "\n",
    "    def compute_loss(self, x, y):\n",
    "        mu, log_var, z = self.encoder(x)\n",
    "        generated = self.decoder(z)\n",
    "        predictions = np.argmax(generated, axis=2)\n",
    "        entropy = CategoricalCrossentropy(y, generated) * self.loss_factor\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + log_var - tf.square(mu) - tf.exp(log_var), axis = 1)\n",
    "        return entropy + kl_loss\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        if isinstance(x, tuple):\n",
    "            x = x[0]\n",
    "            y = y[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.compute_loss(x, y)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": loss\n",
    "        }\n",
    "    # ????\n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ambient-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVAE:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        kernel_size,\n",
    "        encoder_filters,\n",
    "        encoder_strides,\n",
    "        decoder_filters,\n",
    "        decoder_strides,\n",
    "        n_notes,\n",
    "        n_durations,\n",
    "        emb_size,\n",
    "        input_dim,\n",
    "        latent_dim,\n",
    "        loss_factor\n",
    "    ):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.encoder_filters = encoder_filters\n",
    "        self.encoder_strides = encoder_strides\n",
    "        self.decoder_filters = decoder_filters\n",
    "        self.decoder_strides = decoder_strides\n",
    "        self.n_notes = n_notes\n",
    "        self.n_durations = n_durations\n",
    "        self.emb_size = emb_size\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.loss_factor = loss_factor\n",
    "        \n",
    "        self._build_model()\n",
    "        \n",
    "        \n",
    "    def _build_model(self):\n",
    "        \n",
    "        # ENCODER\n",
    "        \n",
    "        notes_in = Input(shape=(self.input_dim))\n",
    "        x_notes = Embedding(self.n_notes, self.emb_size)(notes_in)\n",
    "        durations_in = Input(shape=(self.input_dim))\n",
    "        x_durations = Embedding(self.n_durations, self.emb_size)(durations_in)\n",
    "        x = Concatenate()([x_notes, x_durations])\n",
    "        inp_shape = x.shape[1]\n",
    "        for i in range(len(self.encoder_filters)):\n",
    "            x = Conv1D(self.encoder_filters[i], self.kernel_size, self.encoder_strides[i], padding='same')(x)\n",
    "#             x = BatchNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "        dense_shape = x.shape[1:]\n",
    "        x = Flatten()(x)\n",
    "        self.mu = Dense(self.latent_dim)(x)\n",
    "        self.log_var = Dense(self.latent_dim)(x)\n",
    "        \n",
    "        def sample(args):\n",
    "            mu, log_var = args\n",
    "            epsilon = K.random_normal(shape=K.shape(mu))\n",
    "            return mu + K.exp(log_var / 2) * epsilon\n",
    "        \n",
    "        self.z = Lambda(sample)([self.mu, self.log_var])\n",
    "        self.encoder = Model([notes_in, durations_in], [self.mu, self.log_var, self.z])\n",
    "        \n",
    "        # DECODER\n",
    "        \n",
    "        decoder_input = Input(self.latent_dim)\n",
    "        x = Dense(np.prod(dense_shape))(decoder_input)\n",
    "        x = Reshape(dense_shape)(x)\n",
    "        for i in range(len(self.decoder_filters)):\n",
    "            x = Conv1DTranspose(self.decoder_filters[i], self.kernel_size, self.decoder_strides[i], padding='same')(x)\n",
    "#             x = BatchNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "        x_notes, x_durations = tf.unstack(Reshape((2, inp_shape, self.emb_size))(x), axis=1)\n",
    "        notes_out = Dense(self.n_notes, activation='softmax')(x_notes)\n",
    "        durations_out = Dense(self.n_durations, activation='softmax')(x_durations)\n",
    "        self.decoder = Model(decoder_input, [notes_out, durations_out])\n",
    "        self.model = ModelBuilder(self.encoder, self.decoder, self.loss_factor)\n",
    "        \n",
    "    def compile(self, lr):\n",
    "        self.model.compile(optimizer=Adam(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "experimental-onion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SequenceVAE(\n",
    "    kernel_size = 32,\n",
    "    encoder_filters = [128, 128, 64, 32],\n",
    "    encoder_strides = [1, 2, 2, 1],\n",
    "    decoder_filters = [16, 32, 64, 128],\n",
    "    decoder_strides = [1, 2, 2, 1],\n",
    "    n_notes = len(note_dictionary),\n",
    "    n_durations = len(duration_dictionary),\n",
    "    emb_size = 64,\n",
    "    input_dim = X[0].shape[1],\n",
    "    latent_dim = 2,\n",
    "    loss_factor = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "solid-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "arctic-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n\n    TypeError: train_step() missing 1 required positional argument: 'y'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-619520df5e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3357\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3277\u001b[0m           expand_composites=True)\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/abryl/.cache/pypoetry/virtualenvs/untitled-DiiM6t2A-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n\n    TypeError: train_step() missing 1 required positional argument: 'y'\n"
     ]
    }
   ],
   "source": [
    "model.model.fit(\n",
    "    X, y,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-hobby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-terrorism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
